{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS329E Data Analytics Project\n",
    "\n",
    "**Team Members:** *Bryce Holladay, Joshua Mathew, Austin Rinn, Eddie Castillo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the techniques that we have learned in class, we attempted to predict the result of a National Football League (NFL) play based on elements existing before the play begins, such as field position and time remaining in game.\n",
    "\n",
    "We used data collected from [publiclly available play by play data from the years 2013 through 2019](http://nflsavant.com/about.php) to build our model. As inputs, our model takes parameters such as time, down, yards to go, yardline, and offensive formation. Our data has several play resultant classifiers that we have tried to predict, including touchdowns, interceptions, fumbles, and interception.\n",
    "\n",
    "In order to fit the data into our model, we performed several actions to pre-process it, including reformatting time into a linear format and removing non-descriptive data like season year. The results of our model are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for any notes\n",
    "# Rubric: https://utexas.instructure.com/courses/1275914/assignments/4897667\n",
    "import pandas as pd, numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from sklearn import decomposition  \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Data cleaning, data exploration, and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data from csv\n",
    "#For building purposes use one season to save processing time.\n",
    "#For final runs we will switch to compiled data sheet with all seasons.\n",
    "#Display initial data head\n",
    "\n",
    "play_data = pd.read_csv('pbp-2019.csv')\n",
    "play_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert time into a standard format\n",
    "#Display both format heads for comparison\n",
    "play_data['AbsoluteTime'] = (play_data['Quarter']-1)*900 + play_data['Minute']*60 + play_data['Second']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert GameDate into just month to represent time of year\n",
    "import re\n",
    "pattern = \"-(.*?)\\-\"\n",
    "for index in range(play_data.shape[0]):\n",
    "   play_data['GameDate'][index] = re.search(pattern, play_data['GameDate'][index]).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_data.rename(columns={\"GameDate\": \"GameMonth\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purge other data not needed\n",
    "\n",
    "#Drop Data that has no effect or could mislead models\n",
    "# No longer need Quarter, Minute, Seconds\n",
    "# GameID has no effect on the play\n",
    "# SeriesFirstDown has no description\n",
    "# NextScore is 0 for every row. Has no effect.\n",
    "play_data = play_data.drop(['Quarter', 'Minute', 'Second', 'GameId', 'Unnamed: 10', 'Unnamed: 12', 'Unnamed: 16', 'Unnamed: 17', 'SeriesFirstDown', 'NextScore', 'TeamWin', 'Description', 'OffenseTeam', 'DefenseTeam', 'SeasonYear'], axis=1)\n",
    "\n",
    "# Combine RushDirection and PassType to get one column with play type\n",
    "# No need for PlayType column anymore because it says the same information but less descriptive\n",
    "play_data['RushDirection'] = play_data['RushDirection'].fillna('')\n",
    "play_data['PassType'] = play_data['PassType'].fillna('')\n",
    "play_data['PlayType2'] = play_data['RushDirection'] + play_data['PassType']\n",
    "play_data = play_data.drop('PlayType', axis=1)\n",
    "\n",
    "play_data.rename(columns={\"PlayType\": \"PlayType2\"})\n",
    "play_data = play_data.drop(['PassType', 'RushDirection', 'YardLineDirection'], axis=1)\n",
    "play_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (play_data['PlayType2'] == '').sum()\n",
    "print(c)\n",
    "play_data.head(50)\n",
    "play_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where it is not a rush/pass play\n",
    "# Get names of indexes for which plays are not rush or pass\n",
    "indexNames = play_data[(play_data['IsRush'] == 0) & (play_data['IsPass'] == 0)].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "play_data.drop(indexNames , inplace=True)\n",
    "play_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This took care of most of the nulls. Dropping the rest is a small fraction of our data\n",
    "# Get names of indexes for which plays are not specified\n",
    "indexNames = play_data[play_data['PlayType2'] == ''].index\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "play_data.drop(indexNames , inplace=True)\n",
    "\n",
    "c = (play_data['PlayType2'] == '').sum()\n",
    "print(c)\n",
    "play_data.head(50)\n",
    "play_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encode the categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# creating initial dataframe\n",
    "#bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "#bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "play_data['Formation_Code'] = labelencoder.fit_transform(play_data['Formation'])\n",
    "play_data['PlayType_Code'] = labelencoder.fit_transform(play_data['PlayType2'])\n",
    "\n",
    "play_data_encoded = play_data.drop(['Formation', 'PlayType2'], axis=1)\n",
    "play_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict a touchdown, we must drop data that cannot be known prior to the play\n",
    "play_data_isTD = play_data_encoded.drop(['Yards', 'IsIncomplete', 'IsSack', 'IsChallenge', 'IsChallengeReversed', 'Challenger', 'IsMeasurement', 'IsInterception', 'IsFumble', 'IsPenalty', 'IsTwoPointConversion', 'IsTwoPointConversionSuccessful', 'IsPenaltyAccepted', 'PenaltyTeam', 'PenaltyType', 'PenaltyYards', 'YardLineFixed'], axis=1)\n",
    "play_data_isTD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict an interception, we must drop data that cannot be known prior to the play\n",
    "play_data_isINT = play_data_encoded.drop(['Yards', 'IsFumble', 'IsTouchdown', 'IsChallenge', 'IsChallengeReversed', 'Challenger', 'IsMeasurement', 'IsIncomplete', 'IsSack', 'IsPenalty', 'IsTwoPointConversion', 'IsTwoPointConversionSuccessful', 'IsPenaltyAccepted', 'PenaltyTeam', 'PenaltyType', 'PenaltyYards', 'YardLineFixed'], axis=1)\n",
    "play_data_isINT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict an incomplete pass, we must drop data that cannot be known prior to the play\n",
    "play_data_isIC = play_data_encoded.drop(['Yards', 'IsFumble', 'IsTouchdown', 'IsChallenge', 'IsChallengeReversed', 'Challenger', 'IsMeasurement', 'IsInterception', 'IsSack', 'IsPenalty', 'IsTwoPointConversion', 'IsTwoPointConversionSuccessful', 'IsPenaltyAccepted', 'PenaltyTeam', 'PenaltyType', 'PenaltyYards', 'YardLineFixed'], axis=1)\n",
    "\n",
    "# Incomplete only applies to passing plays. Must drop all rows where isRush = 1\n",
    "rows = play_data_isIC['IsRush'] == 1\n",
    "indexNames = play_data_isIC[rows].index\n",
    "play_data_isIC = play_data_isIC.drop(indexNames)\n",
    "\n",
    "play_data_isIC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict a fumble, we must drop data that cannot be known prior to the play\n",
    "play_data_isFum = play_data_encoded.drop(['Yards', 'IsIncomplete', 'IsTouchdown', 'IsChallenge', 'IsChallengeReversed', 'Challenger', 'IsMeasurement', 'IsInterception', 'IsSack', 'IsPenalty', 'IsTwoPointConversion', 'IsTwoPointConversionSuccessful', 'IsPenaltyAccepted', 'PenaltyTeam', 'PenaltyType', 'PenaltyYards', 'YardLineFixed'], axis=1)\n",
    "play_data_isFum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set features and labels\n",
    "\n",
    "#for touchdowns\n",
    "labels_TD = play_data_isTD['IsTouchdown']\n",
    "features_TD = play_data_isTD.drop(['IsTouchdown'], axis=1)\n",
    "\n",
    "#for interceptions\n",
    "labels_Int = play_data_isINT['IsInterception']\n",
    "features_Int = play_data_isINT.drop(['IsInterception'], axis=1)\n",
    "\n",
    "#for fumbles\n",
    "labels_Fum = play_data_isFum['IsFumble']\n",
    "features_Fum = play_data_isFum.drop(['IsFumble'], axis=1)\n",
    "\n",
    "#for incompletes\n",
    "labels_IC = play_data_isIC['IsIncomplete']\n",
    "features_IC = play_data_isIC.drop(['IsIncomplete'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree_Football(features, labels):\n",
    "\n",
    "    #Scale features\n",
    "    ss = StandardScaler()\n",
    "    features_scaled = ss.fit_transform(X=features)\n",
    "    features_scaled = pd.DataFrame(features_scaled)\n",
    "\n",
    "    #Split data into training and test data\n",
    "    features_train, features_test, labels_train, labels_test = sk.model_selection.train_test_split(features_scaled, labels, test_size=.2)\n",
    "\n",
    "    #Perform PCA\n",
    "    pca = PCA(n_components = 0.95, svd_solver='full')\n",
    "    features_train_pca = pca.fit_transform(features_train)\n",
    "    features_train_pca = pd.DataFrame(features_train_pca)\n",
    "    num_columns = len(features_train_pca.columns)\n",
    "\n",
    "    features_test_pca = pca.transform(features_test)[:, :num_columns]\n",
    "    features_test_pca = pd.DataFrame(features_test_pca)\n",
    "\n",
    "    #Perform 10-fold cross validation on decision tree\n",
    "    k_fold_tree = tree.DecisionTreeClassifier()\n",
    "    cross_score = cross_val_score(k_fold_tree, features_scaled, labels, cv = 10)\n",
    "\n",
    "    #Tune model with best parameters using GridSearch\n",
    "    grid_tree = tree.DecisionTreeClassifier()\n",
    "    grid_search = GridSearchCV(grid_tree, \n",
    "                          {'max_depth': [5,10,15,20,25],\n",
    "                          'min_samples_leaf': [5,10,15,20],\n",
    "                          'max_features': [2,4,6,8,10]},\n",
    "                          cv = 10, scoring = 'accuracy')\n",
    "    grid_search.fit(features_scaled, labels)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    #Pass GridSearchCV into cross_val_score\n",
    "    final_report = cross_val_score(grid_search, features_scaled, labels, cv = 10)\n",
    "    avg_accuracy = final_report.mean()\n",
    "\n",
    "    vals = [best_params, final_report, avg_accuracy]\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9373757352318206\n",
      "Accuracy for predicting touchdowns using Decision Trees: 0.9373757352318206\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees for Touchdowns\n",
    "\n",
    "#Call Decision Tree method\n",
    "TD_vals_DT = Decision_Tree_Football(features_TD, labels_TD)\n",
    "TD_best_params = TD_vals_DT[0]\n",
    "TD_DT_accuracy = TD_vals_DT[2]\n",
    "\n",
    "print(str(TD_best_para))\n",
    "print('Accuracy for predicting touchdowns using Decision Trees: ' + str(TD_DT_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting interceptions using Decision Trees: 0.9856508858383302\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees for Interceptions\n",
    "\n",
    "#Call Decision Tree method\n",
    "Int_vals_DT = Decision_Tree_Football(features_Int, labels_Int)\n",
    "Int_best_params = Int_vals_DT[0]\n",
    "Int_DT_accuracy = Int_vals_DT[2]\n",
    "\n",
    "print('Accuracy for predicting interceptions using Decision Trees: ' + str(Int_DT_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting fumbles using Decision Trees: 0.9912311389431917\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees for Fumbles\n",
    "\n",
    "#Call Decision Tree method\n",
    "Fum_vals_DT = Decision_Tree_Football(features_Fum, labels_Fum)\n",
    "Fum_best_params = Fum_vals_DT[0]\n",
    "Fum_DT_accuracy = Fum_vals_DT[2]\n",
    "\n",
    "print('Accuracy for predicting fumbles using Decision Trees: ' + str(Fum_DT_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting incomplete passes using Decision Trees: 0.6626137418074025\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees for Incomplete Passes\n",
    "\n",
    "#Call Decision Tree method\n",
    "IC_vals_DT = Decision_Tree_Football(features_IC, labels_IC)\n",
    "IC_best_params = IC_vals_DT[0]\n",
    "IC_DT_accuracy = IC_vals_DT[2]\n",
    "\n",
    "print('Accuracy for predicting incomplete passes using Decision Trees: ' + str(IC_DT_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Football(features, labels):\n",
    "    \n",
    "    #Scale features\n",
    "    standard_scaler = StandardScaler()\n",
    "    features_scaled = standard_scaler.fit_transform(X=features)\n",
    "    features_scaled = pd.DataFrame(features_scaled)\n",
    "    \n",
    "    #Create KNeighborsClassifier()\n",
    "    numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    knn_grid_search = GridSearchCV(KNeighborsClassifier(), param_grid = {'n_neighbors': numbers}, cv = 10, scoring = 'accuracy')\n",
    "    knn_grid_search = knn_grid_search.fit(features_scaled, labels) \n",
    "    best_params = knn_grid_search.best_params_\n",
    "    \n",
    "    #Pass GridSearchCV into cross_val_score\n",
    "    final_report = cross_val_score(knn_grid_search, features_scaled, labels, cv = 10)\n",
    "    avg_accuracy = final_report.mean()\n",
    "    return [best_params, final_report, avg_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting touchdowns using K-Nearest Neighbors: 0.9301682397830874\n"
     ]
    }
   ],
   "source": [
    "#KNN for Touchdowns\n",
    "\n",
    "#Call KNN method\n",
    "TD_vals_KNN = KNN_Football(features_TD, labels_TD)\n",
    "TD_KNN_best_params = TD_vals_KNN[0]\n",
    "TD_KNN_accuracy = TD_vals_KNN[2]\n",
    "\n",
    "print('Accuracy for predicting touchdowns using K-Nearest Neighbors: ' + str(TD_KNN_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for Interceptions\n",
    "\n",
    "#Call NKNN method\n",
    "Int_vals_KNN = KNN_Football(features_Int, labels_Int)\n",
    "Int_KNN_best_params = Int_vals_KNN[0]\n",
    "Int_KNN_accuracy = Int_vals_KNN[2]\n",
    "\n",
    "print('Accuracy for predicting interceptions using K-Nearest Neighbors: ' + str(Int_KNN_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for Fumbles\n",
    "\n",
    "#Call Decision Tree method\n",
    "Fum_vals_KNN = KNN_Football(features_Fum, labels_Fum)\n",
    "Fum_KNN_best_params = Fum_vals_KNN[0]\n",
    "Fum_KNN_accuracy = Fum_vals_KNN[2]\n",
    "\n",
    "print('Accuracy for predicting fumbles using K-Nearest Neighbors: ' + str(Fum_KNN_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for Incomplete Passes\n",
    "\n",
    "#Call Decision Tree method\n",
    "IC_vals_KNN = KNN_Football(features_IC, labels_IC)\n",
    "IC_KNN_best_params = IC_vals_KNN[0]\n",
    "IC_KNN_accuracy = IC_vals_KNN[2]\n",
    "\n",
    "print('Accuracy for predicting incomplete passes using K-Nearest Neighbors: ' + str(IC_KNN_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes_Football(features, labels):\n",
    "    \n",
    "    #Naive Bayes uses a probabilistic approach, which scales with changes in data.\n",
    "    gaussian_classifier = GaussianNB()\n",
    "    cv_accuracy = cross_val_score(gaussian_classifier, features, labels, cv = 10).mean() \n",
    "    return cv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes for Touchdowns\n",
    "\n",
    "#Call Naive Bayes method\n",
    "print('Accuracy for predicting touchdowns using K-Nearest Neighbors: ' + str(Naive_Bayes_Football(features_TD, labels_TD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes for Interceptions\n",
    "\n",
    "#Call Naive Bayes method\n",
    "print('Accuracy for predicting interceptions using K-Nearest Neighbors: ' + str(Naive_Bayes_Football(features_Int, labels_Int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes for Fumbles\n",
    "\n",
    "#Call Naive Bayes method\n",
    "print('Accuracy for predicting fumbles using K-Nearest Neighbors: ' + str(Naive_Bayes_Football(features_Fum, labels_Fum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes for Incomplete Passes\n",
    "\n",
    "#Call Naive Bayes method\n",
    "print('Accuracy for predicting fumbles using K-Nearest Neighbors: ' + str(Naive_Bayes_Football(features_IC, labels_IC)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neural_Net_Football(features, labels):\n",
    "\n",
    "    #Create the scaler\n",
    "    standard_scaler = StandardScaler()\n",
    "\n",
    "    #Create the multi-layer perceptron\n",
    "    mlp = MLPClassifier()\n",
    "    neural_pipeline = Pipeline(steps = [('scaler', standard_scaler), ('mlpclassifier', mlp)])\n",
    "    mlp_parameters = {'mlpclassifier__hidden_layer_sizes': [(10,)], 'mlpclassifier__activation':['logistic', 'tanh', 'relu']} # hidden layers of from 10-20 with gaps of 10\n",
    "\n",
    "    #Tune model with best parameters using GridSearch\n",
    "    mlp_grid_search = GridSearchCV(neural_pipeline, param_grid = mlp_parameters, cv = 5, scoring = 'accuracy')\n",
    "    mlp_grid_search.fit(features, labels)\n",
    "    best_params = mlp_grid_search.best_params_\n",
    "\n",
    "    #Pass GridSearchCV into cross_val_score\n",
    "    final_report = cross_val_score(mlp_grid_search, features, labels, cv = 10)\n",
    "    avg_accuracy = final_report.mean()\n",
    "\n",
    "    return [best_params, final_report, avg_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting touchdowns using Decision Trees: 0.9429194284968208\n"
     ]
    }
   ],
   "source": [
    "#Neural Nets for Touchdowns\n",
    "\n",
    "#Call Neural Network method\n",
    "TD_vals_NN = Neural_Net_Football(features_TD, labels_TD)\n",
    "TD_best_params = TD_vals_NN[0]\n",
    "TD_NN_accuracy = TD_vals_NN[2]\n",
    "\n",
    "print('Accuracy for predicting touchdowns using Neural Networks: ' + str(TD_NN_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting interceptions using Decision Trees: 0.985338999495248\n"
     ]
    }
   ],
   "source": [
    "#Neural Nets for Interceptions\n",
    "\n",
    "#Call Neural Network method\n",
    "Int_vals_NN = Neural_Net_Football(features_Int, labels_Int)\n",
    "Int_best_params = Int_vals_NN[0]\n",
    "Int_NN_accuracy = Int_vals_NN[2]\n",
    "\n",
    "print('Accuracy for predicting interceptions using Neural Networks: ' + str(Int_NN_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting fumbles using Decision Trees: 0.9912311389431917\n"
     ]
    }
   ],
   "source": [
    "#Neural Nets for Fumbles\n",
    "\n",
    "#Call Decision Tree method\n",
    "Fum_vals_NN = Neural_Net_Football(features_Fum, labels_Fum)\n",
    "Fum_best_params = Fum_vals_NN[0]\n",
    "Fum_NN_accuracy = Fum_vals_NN[2]\n",
    "\n",
    "print('Accuracy for predicting fumbles using Neural Networks: ' + str(Fum_NN_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for predicting incomplete passes using Decision Trees: 0.6720319090423775\n"
     ]
    }
   ],
   "source": [
    "#Neural Nets for Incomplete Passes\n",
    "\n",
    "#Call Decision Tree method\n",
    "IC_vals_NN = Neural_Net_Football(features_IC, labels_IC)\n",
    "IC_best_params = IC_vals_NN[0]\n",
    "IC_NN_accuracy = IC_vals_NN[2]\n",
    "\n",
    "print('Accuracy for predicting incomplete passes using Neural Networks: ' + str(IC_NN_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forests_Football(features, labels):\n",
    "    \n",
    "    #Create the Random Forest Classifier\n",
    "    random_forest_classifier = RandomForestClassifier()\n",
    "    forest_parameters = {'max_depth': [5, 10, 15, 20, 25], \n",
    "                         'min_samples_leaf': [5, 10, 15, 20], \n",
    "                         'max_features': ['sqrt', 'log2']}\n",
    "    \n",
    "    #Tune model with best parameters using GridSearch\n",
    "    forest_grid_search = GridSearchCV(random_forest_classifier, param_grid = forest_parameters, cv = 5, scoring = 'accuracy')\n",
    "    forest_grid_search = forest_grid_search.fit(features, labels)\n",
    "    best_params = forest_grid_search.best_params_\n",
    "\n",
    "    #Pass GridSearchCV into cross_val_score\n",
    "    final_report = cross_val_score(forest_grid_search, features, labels, cv = 10)\n",
    "    avg_accuracy = final_report.mean()\n",
    "\n",
    "    return [best_params, final_report, avg_accuracy]\n",
    "\n",
    "def Ada_Boost_Football(features, labels):\n",
    "    \n",
    "    #Create the ADA Boost Classifier\n",
    "    ada_boost_classifier = AdaBoostClassifier()\n",
    "    ada_parameters = {'n_estimators': list(range(50, 151, 25))}\n",
    "    \n",
    "    #Tune model with best parameters using GridSearch\n",
    "    ada_grid_search = GridSearchCV(ada_boost_classifier, param_grid = ada_parameters, cv = 5, scoring = 'accuracy')\n",
    "    ada_grid_search = ada_grid_search.fit(features, labels)\n",
    "    best_params = ada_grid_search.best_params_\n",
    "\n",
    "    #Pass GridSearchCV into cross_val_score\n",
    "    final_report = cross_val_score(ada_grid_search, features, labels, cv = 10)\n",
    "    avg_accuracy = final_report.mean()\n",
    "    \n",
    "    return [best_params, final_report, avg_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests and ADA Boost for Touchdowns\n",
    "\n",
    "#Call Random Forests method\n",
    "TD_vals_RF = Random_Forests_Football(features_TD, labels_TD)\n",
    "TD_RF_best_params = TD_vals_RF[0]\n",
    "TD_RF_accuracy = TD_vals_RF[2]\n",
    "\n",
    "#Call ADA Boost method\n",
    "TD_vals_AB = Ada_Boost_Football(features_TD, labels_TD)\n",
    "TD_AB_best_params = TD_vals_AB[0]\n",
    "TD_AB_accuracy = TD_vals_AB[2]\n",
    "\n",
    "print('Accuracy for predicting touchdowns using Random Forests: ' + str(TD_RF_accuracy))\n",
    "print('Accuracy for predicting touchdowns using ADA Boost: ' + str(TD_AB_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests and ADA Boost for Interceptions\n",
    "\n",
    "#Call Random Forests method\n",
    "Int_vals_RF = Random_Forests_Football(features_Int, labels_Int)\n",
    "Int_RF_best_params = Int_vals_RF[0]\n",
    "Int_RF_accuracy = Int_vals_RF[2]\n",
    "\n",
    "#Call ADA Boost method\n",
    "Int_vals_AB = Ada_Boost_Football(features_Int, labels_Int)\n",
    "Int_AB_best_params = Int_vals_AB[0]\n",
    "Int_AB_accuracy = Int_vals_AB[2]\n",
    "\n",
    "print('Accuracy for predicting interceptions using Random Forests: ' + str(Int_RF_accuracy))\n",
    "print('Accuracy for predicting interceptions using ADA Boost: ' + str(Int_AB_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests and ADA Boost for Fumbles\n",
    "\n",
    "#Call Random Forests method\n",
    "Fum_vals_RF = Random_Forests_Football(features_Fum, labels_Fum)\n",
    "Fum_RF_best_params = Fum_vals_RF[0]\n",
    "Fum_RF_accuracy = Fum_vals_RF[2]\n",
    "\n",
    "#Call ADA Boost method\n",
    "Fum_vals_AB = Ada_Boost_Football(features_Fum, labels_Fum)\n",
    "Fum_AB_best_params = Fum_vals_AB[0]\n",
    "Fum_AB_accuracy = Fum_vals_AB[2]\n",
    "\n",
    "print('Accuracy for predicting fumbles using Random Forests: ' + str(Fum_RF_accuracy))\n",
    "print('Accuracy for predicting fumbles using ADA Boost: ' + str(Fum_AB_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests and ADA Boost for Incomplete Passes\n",
    "\n",
    "#Call Random Forests method\n",
    "IC_vals_RF = Random_Forests_Football(features_IC, labels_IC)\n",
    "IC_RF_best_params = IC_vals_RF[0]\n",
    "IC_RF_accuracy = IC_vals_RF[2]\n",
    "\n",
    "#Call ADA Boost method\n",
    "IC_vals_AB = Ada_Boost_Football(features_IC, labels_IC)\n",
    "IC_AB_best_params = IC_vals_AB[0]\n",
    "IC_AB_accuracy = IC_vals_AB[2]\n",
    "\n",
    "print('Accuracy for predicting incomplete passes using Random Forests: ' + str(IC_RF_accuracy))\n",
    "print('Accuracy for predicting incomplete passes using ADA Boost: ' + str(IC_AB_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare accuracy scores and other metrics for our different models.\n",
    "#How confident are we in the success rates of these various models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discuss which model was the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discuss data. What issues may have existed in the data?  What assumptions did we make? What could have made our data better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discuss our project as a whole. How could we have improved project? How might this model be used in real world applications?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
